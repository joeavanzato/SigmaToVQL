# SigmaToVQL
 
### What is it?

SigmaToVQL is a utility designed to facilitate engaging with the Velociraptor Sigma processing engine.  It provides a mechanism to quickly utilize Sigma logic over the results of any row-producing artifact, including the use of in-line variables defined within the Sigma rules as well as supporting arbitrary parameter inputs to artifacts and the use of specific named sources within the artifact.

Sigma has traditionally been used against Windows Event Logs and similar types of 'log' sources - with the power of Velociraptor, we can quickly stage VQL to leverage Sigma rules against any and all artifacts, not just the 'traditional' Sigma log sources.


#### Usecase Ideas to Get You Excited

* Write a correlation rule looking for mimikatz followed by a suspicious extension (dmp, zip, tmp, etc) in suspicious directories across file-based artifacts like the MFT or USN Journal.
* Use existing network_connection rules to hunt inside of the enriched netstat artifact
* Use DNS rules to inspect DNSCache or similar artifacts
* Use process_creation rules to look across running processes, prefetch, etc
* Develop custom rules inspecting Scheduled Tasks/Services for suspicious arguments, binary paths, etc
* Use ps_script rules to target even more items such as ConsoleHost_history.txt files

In general, the goal is to support as many existing Sigma rules as possible while allowing analysts to easily write their own rules specific to individual forensic artifacts.

### Example Usage

Let's walk through a basic example to show the power and flexibility of this approach.

* As an analyst, you may want to quickly develop and iterate on a Sigma rule designed to detect suspicious terms in PowerShell's ConsoleHost_history files.
  * Let's imagine you write the below Sigma for this as a basic example based on the known Artifact output field of 'Line' (omitting Sigma rule fields such as references, tags, author, etc)
  * ```yaml
    title: Suspicious Terms in ConsoleHost_history
    description: Checks ConsoleHost_history.txt files for terms often associated with threat actor abuse.
    logsource:
        category: system
        product: windows
        service: psreadline
    detection:
        selection:
            Line|contains: [reflection, downloadstring, sockets, rc4bytestream, disablerealtimemonitoring]
        condition: selection
    level: medium
    ```
  * This rule checks if any of the terms listed appear in the 'Line' column and raises a result if so - but how do we actually get this to run against the expected artifact?
* Sigma works using the concept of Log Sources - those values defined as category, product and service - SigmaToVQL uses these to tell Velociraptor which rules should be matched against which artifacts - the next step is ensuring that the specified values align in the artifact mapping provided to SigmaToVQL - SigmaToVQL ships with artifact_map.yaml to get you started.
  * The snippet below shows an example artifact map that corresponds to the above Sigma logsource
  * ```yaml
    - artifact_name: Windows.System.Powershell.PSReadline
      artifact_subsource:
      sigma_logmap:
        category: system
        product: windows
        service: psreadline
      field_map:
  * artifact_subsource is only needed if there is a **named source** inside the artifact - if yes, then a subsource should be specified and the map should be built uniquely for that source
  * field_map can be null but is useful for explicitly mapping fields from within the artifact to different names - for example, normalizing data from multiple artifacts to a common set of field names
* This will now work as is - when we launch sigma_to_vql.py and tell it where to find our input Sigma Rules and Artifact Map, it will do a few things:
  * Iterate over all Sigma rules, perform some basic validation and merge them into a single file per-logsource
  * Build a templated VQL artifact that includes log-source mapping, field mappings and launches the Sigma engine against the specified log source
    * An individual named-source is included in the artifact on a per-logsource basis
    * An example of this output is shown below:
    * ```yaml
        author: Autogenerated by github.com/joeavanzato/SigmaToVQL
        description: Defines Sigma Log Sources/Field Mappings and executes relevant queries on a Velociraptor Client
        name: Custom.SigmaToVQL.Merged
        sources:
        - name: Windows.System.Powershell.PSReadline
          query: |-
            LET LogSources <= sigma_log_sources(
                `system/windows/psreadline` = {
                SELECT * FROM Artifact.Windows.System.Powershell.PSReadline()
                }
            )
            LET FieldMapping <= dict(
            )
            LET RulePath = "C:\\Users\\Joe\\Documents\\GitHub\\SigmaToVQL\\output\\merged_rules\\system_windows_psreadline.yaml"
            LET Rules = read_file(filename=RulePath, length=10000000)
            SELECT * FROM sigma(rules=split(string=Rules, sep_string="---"),log_sources=LogSources,debug=False,field_mapping=FieldMapping)
        type: CLIENT
        ```
    * This artifact can then be loaded into Velociraptor, at which point it can be bundled with the associated YAML rules and deployed to clients.

At it's core - that's it - the full power of the Sigma engine can be used against any artifact, all it takes is a basic map to get going and SigmaToVQL comes with most of the pre-canned artifacts already mapped out.


### Advanced Features

SigmaToVQL supports a few more features that will prove useful for most analysts:
* In-line Variable Replacement for Sigma Rules (globally or per-logsource)
* Passing parameters to artifacts based on command-line or an input arguments file (globally or per-artifact)

#### Variables in Sigma Rules

It is possible to define variables for easier modification and inclusion across multiple Sigma rules.

SigmaToVQL does not use a traditional Sigma processing pipeline at this time (although it's certainly possible to include this as a pre-processing step and one is being worked on to support easier use).

Instead, variables are simply replaced in-line as rules are being validated.  Variables are defined in a rule like below:

```yaml
    title: Suspicious Terms in ConsoleHost_history
    description: Checks ConsoleHost_history.txt files for terms often associated with threat actor abuse.
    logsource:
        category: system
        product: windows
        service: psreadline
    detection:
        selection:
            Line|contains: '%suspicious_terms%'
        condition: selection
    level: medium
```

SigmaToVQL supports the loading of a 'variables.yaml' file containing variable definitions - an example one supporting the above variable is shown below:

```yaml
global:
  suspicious_terms: [val1, val2]
specific:
  system\windows\psreadline:
    suspicious_terms: [mimikatz]
```
In the above examples, if we hadn't defined a specific variable for system\windows\psreadline, the value would have expanded to the global [val1, val2] - since we have, the value will expand in the final rule to [mimikatz], shown below:
```yaml
    title: Suspicious Terms in ConsoleHost_history
    description: Checks ConsoleHost_history.txt files for terms often associated with threat actor abuse.
    logsource:
        category: system
        product: windows
        service: psreadline
    detection:
        selection:
            Line|contains: 
              - mimikatz
        condition: selection
    level: medium
```
This is particularly useful for having common variables shared among and available to all rules.

#### Artifact Parameters

Artifacts in Velociraptor support passing in parameters (arguments) when invoking them - we can do the same thing when preparing them for use as a Sigma logsource.  

Parameters can be passed in via the command-line as an arbitrary argument (```sigma_to_vql.py --key=value```) or setup in arguments.yaml (or similar) to serve as a more repeatable foundation for building the final artifact.  

Arguments can be global (applied to any artifact containing the parameter) or per-artifact (only applied to that specific named artifact) - this allows for flexibility such as passing two different values to artifacts with the same-named parameter.

Per-artifact parameters take priority over global parameters if an artifact has both - additionally, global artifacts are **only applied to an artifact if it holds the corresponding key in the artifact map.**

At the same time, if a per-artifact parameter is specified, it is forcefully-applied to the artifact regardless of the map - so make sure it actually exists!

An example implementation is shown below - first we look at an example from the artifact map:
```yaml
- artifact_name: Windows.NTFS.MFT
  artifact_subsource:
  sigma_logmap:
    category: filesystem
    product: windows
    service: mft
  field_map:
    FileName: FileName
  parameters:
    DateAfter:
```
The above mapping contains a parameter named DateAfter - if we specify this parameter at a global level, the value will be inserted into this artifact when we execute it.  We can also store it in a configuration 'arguments.yaml' file as shown below:
```yaml
global:
  DateAfter: 2024-10-01T00:00:00Z
specific:
  Windows.NTFS.MFT:
    DateBefore: 2024-10-07T00:00:00Z
    AllNtfs: True
```
In the above case, both parameters specified under Windows.NTFS.MFT will be applied to the artifact while DateAfter will be applied to any other artifact where it is specified in the artifact map.  This is particularly useful to modify prior to an engagement and to quickly affect all relevant artifacts.

#### Artifact Maps
Maps primarily serve to tell the Sigma engine what category, product and service a specific artifact (and named source inside of that artifact) should align to when checking for relevant Sigma rules.

In general, artifact maps are written to align to the standardized Sigma log sources whenever possible (https://sigmahq.io/docs/basics/log-sources.html).

* **category**: attempting to align as much as possible to default sigma categories - but sometimes not possible
  * As an example - for Prefetch, we could use process_creation since there is a small amount of shared data there
  * MFT we could use file_access as the most relevant one although file_creation and file_event are both possible - we can define separate maps for each as needed
* **product**: windows/linux/mac/etc
* **service**: distinct identifier for the artifact AND named source if applicable
  * Generic.Forensic.SQLiteHunter - Chromium Browser Extensions -> sqlitehunter\chromium\extensions

Maps can also have a few other fields that are useful for both VQL and Sigma:
* **field_map** - A dictionary representing field normalizations for VQL events - Key is the destination field name and Value is the current VQL Field Name (supports dot-notation for nested fields)
```yaml
field_map:
  FileName: Name
```
Field Mappings are useful for normalizing columns, especially when using 'out of the box' Sigma rules for generic log sources like process_creation, etc.

* **parameters** - If any keys are specified here, they will be replaced by 'global' parameters in arguments.yaml or at command-line
  * If you wish to have a parameter forced onto a specific artifact, you can supply it as a local argument inside arguments.yaml like below
```yaml
global:
  DateAfter: 2024-10-01T00:00:00Z
  DateBefore: 2024-11-01T00:00.00Z
local:
  Windows.NTFS.MFT:
    AllNtfs: True
```
Local Parameters are forcefully applied and replace any existing global parameter values - be sure that the parameter exists or else the VQL will fail to produce rows.

* **artifact_subsource** - The named source within the artifact that this mapping should apply to if there are multiple sources

* **select_addon** - Any additional logic we want to include following 'SELECT *' on the artifact 
  * As an example, some rules such as those for network_connection rely on a column normalized as 'Initiated' to equal TRUE 
  * If we want to run those same rules against the netstat_enriched artifact, it does not contain such a column - but we can typically assume that these connections are indeed initiated by the host
  * Thus, we can add the column artifically to support the rules like below
  * ```yaml
    - artifact_name: Windows.Network.NetstatEnriched
      artifact_subsource:
      sigma_logmap:
        product: windows
        category: network_connection
      field_map:
        User: Username
        Image: Path
        CommandLine: CommandLine
        SourcePort: SrcPort
        DestinationPort: DestPort
        DestinationIp: DestIP
        Protocol: Type
      select_addon: ",True AS Initiated"
    ```
    * This will then augment the relevant VQL to be 'SELECT *,True AS Initiated FROM...', adding the colum in question



